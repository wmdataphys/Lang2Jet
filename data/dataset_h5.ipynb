{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8dd57bb",
   "metadata": {},
   "source": [
    "## Preprocess JetClass dataset and save it in .h5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3713a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import vector\n",
    "import uproot\n",
    "vector.register_awkward()\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b86173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_jet_data(parquet_file, labels, config, h5_file):\n",
    "    data = ak.from_parquet(parquet_file)\n",
    "    print(f\"Loaded {len(data)} jets from {parquet_file}\")\n",
    "    idx = np.random.permutation(len(data))\n",
    "    data = data[idx]\n",
    "    p4 = vector.zip({\n",
    "        \"px\": data[\"part\"][\"px\"],\n",
    "        \"py\": data[\"part\"][\"py\"],\n",
    "        \"pz\": data[\"part\"][\"pz\"],\n",
    "        \"energy\": data[\"part\"][\"energy\"]\n",
    "    })\n",
    "    p4_jet = ak.sum(p4, axis=1)\n",
    "\n",
    "    raw_data = ak.zip({\n",
    "        \"part_px\": data[\"part\"][\"px\"],\n",
    "        \"part_py\": data[\"part\"][\"py\"],\n",
    "        \"part_pz\": data[\"part\"][\"pz\"],\n",
    "        \"part_eta\": p4.eta,\n",
    "        \"part_phi\": p4.phi,\n",
    "        \"part_pT\": p4.pt,\n",
    "        \"part_etarel\": p4.deltaeta(p4_jet),\n",
    "        \"part_phirel\": p4.deltaphi(p4_jet),\n",
    "    })\n",
    "\n",
    "        # Apply cuts\n",
    "    cuts = (np.abs(raw_data[\"part_etarel\"]) < 0.8) & (np.abs(raw_data[\"part_phirel\"]) < 0.8)\n",
    "    raw_data = raw_data[cuts]\n",
    "            # Filter jets with enough constituents\n",
    "    particle_count = ak.count(raw_data[\"part_pT\"], axis=1)\n",
    "    valid_jets = (particle_count >= config.min_constituent)\n",
    "    raw_data = raw_data[valid_jets]\n",
    "    label_data = ak.zip({label: data[label] for label in labels})[valid_jets]\n",
    "\n",
    "    # Sort and transform\n",
    "    sorted_indices = ak.argsort(raw_data[\"part_pT\"], ascending=False, axis=1)\n",
    "    sorted_data = raw_data[sorted_indices]\n",
    "    sorted_data[\"part_pT\"] = np.log(sorted_data[\"part_pT\"]) - 1.8\n",
    "\n",
    "    # Pad and stack features\n",
    "    max_particles = config.max_particles\n",
    "    scaling_factor = config.scaling_factor\n",
    "    part_pT = ak.fill_none(ak.pad_none(sorted_data[\"part_pT\"], max_particles, clip=True), 0)\n",
    "    part_etarel = ak.fill_none(ak.pad_none(sorted_data[\"part_etarel\"], max_particles, clip=True), 0)\n",
    "    part_phirel = ak.fill_none(ak.pad_none(sorted_data[\"part_phirel\"], max_particles, clip=True), 0)\n",
    "    features = ak.concatenate([\n",
    "        part_pT[:, :, None],\n",
    "        (part_etarel * scaling_factor)[:, :, None],\n",
    "        (part_phirel * scaling_factor)[:, :, None]\n",
    "    ], axis=-1)\n",
    "\n",
    "    # Labels\n",
    "    label_array_2d = ak.to_numpy([[row[label] for label in labels] for row in label_data])\n",
    "    labels_array = np.argmax(label_array_2d, axis=1)\n",
    "\n",
    "    # Convert to numpy for HDF5\n",
    "    features_np = ak.to_numpy(features)\n",
    "    masks = (features_np[:, :, 0] != 0).astype(np.float32)\n",
    "    \n",
    "    num_jets = len(labels_array)\n",
    "    event_ids = np.arange(num_jets)\n",
    "\n",
    "    # Save to .h5\n",
    "    with h5py.File(h5_file, \"w\") as f:\n",
    "        f.create_dataset(\"pf_features\", data=features_np, compression=\"gzip\")\n",
    "        f.create_dataset(\"pf_mask\", data=masks, compression=\"gzip\")\n",
    "        f.create_dataset(\"label\", data=labels_array, compression=\"gzip\")\n",
    "        f.create_dataset(\"event_id\", data=event_ids, compression=\"gzip\")   # adding event_id so we\n",
    "\n",
    "\n",
    "    print(f\"Saved preprocessed data to {h5_file}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e926039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sciclone/home/hnayak/scr10/Transfer_Learning/dataset/test_20M/train/train.parquet\n",
      "['label_QCD', 'label_Tbqq']\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "cfg = OmegaConf.load(\"../config/config_parquet.yaml\")\n",
    "print(cfg['data']['train_dir'])\n",
    "print(cfg['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b17b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000000 jets from /sciclone/home/hnayak/scr10/Transfer_Learning/dataset/test_20M/train/train.parquet\n",
      "Saved preprocessed data to jetclass_train_preprocessed.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocess_jet_data(cfg['data']['train_dir'], cfg['labels'], cfg, \"jetclass_train_preprocessed.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae5d36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 jets from /sciclone/home/hnayak/scr10/Transfer_Learning/dataset/test_20M/val/val.parquet\n",
      "Saved preprocessed data to jetclass_val_preprocessed.h5\n"
     ]
    }
   ],
   "source": [
    "preprocess_jet_data(cfg['data']['val_dir'], cfg['labels'], cfg, \"jetclass_val_preprocessed.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa601ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000000 jets from /sciclone/home/hnayak/scr10/Transfer_Learning/dataset/test_20M/test/test.parquet\n",
      "Saved preprocessed data to jetclass_test_preprocessed.h5\n"
     ]
    }
   ],
   "source": [
    "preprocess_jet_data(cfg['data']['test_dir'], cfg['labels'], cfg, \"jetclass_test_preprocessed.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6938375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['event_id', 'label', 'pf_features', 'pf_mask']>\n",
      "(1990243, 128, 3)\n",
      "(1990243, 128)\n",
      "(1990243,)\n",
      "float64\n",
      "float32\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"/sciclone/home/hnayak/scr10/Transfer_Learning/data/jetclass_train_preprocessed.h5\", \"r\") as f:\n",
    "    print(f.keys())\n",
    "    print(f['pf_features'].shape)\n",
    "    print(f['pf_mask'].shape)\n",
    "    print(f['label'].shape)\n",
    "    print(f['pf_features'].dtype)\n",
    "    print(f['pf_mask'].dtype)\n",
    "    print(f['label'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1997a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  h5py.File(\"/sciclone/home/hnayak/scr10/Transfer_Learning/dataset/top_quark_dataset/test.h5\", \"r\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6650a994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['table']>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70de1704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995132\n"
     ]
    }
   ],
   "source": [
    "from dataset import MultiClassJetDataset\n",
    "dataset = MultiClassJetDataset(\"/sciclone/home/hnayak/scr10/Transfer_Learning/data/jetclass_test_preprocessed.h5\")\n",
    "print (len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d576caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 3]) torch.Size([1, 128]) torch.Size([1]) torch.Size([1])\n",
      "tensor([[[ 2.5733e+00, -1.4225e-02, -2.6030e-01],\n",
      "         [ 2.4845e+00,  7.9609e-02,  6.4605e-02],\n",
      "         [ 2.0133e+00,  1.5142e-01,  5.4746e-02],\n",
      "         [ 1.9797e+00,  9.3986e-02,  5.8190e-02],\n",
      "         [ 1.9063e+00,  1.4691e-01,  7.0281e-02],\n",
      "         [ 1.8047e+00, -1.6003e-03, -2.7472e-01],\n",
      "         [ 1.6587e+00,  9.1668e-02,  4.3957e-02],\n",
      "         [ 1.6528e+00, -9.3245e-03, -2.9003e-01],\n",
      "         [ 1.5666e+00,  1.4648e-01,  8.4111e-02],\n",
      "         [ 1.4410e+00, -9.7422e-02,  4.1950e-01],\n",
      "         [ 1.2628e+00,  1.5879e-04, -2.6866e-01],\n",
      "         [ 1.2300e+00, -2.8788e-01,  4.6101e-01],\n",
      "         [ 8.8006e-01, -1.9393e-02, -2.7397e-01],\n",
      "         [ 6.6410e-01,  1.2717e-01,  7.2722e-02],\n",
      "         [ 6.2907e-01, -2.0264e-01,  3.6536e-01],\n",
      "         [ 6.0362e-01, -3.5567e-02, -2.8543e-01],\n",
      "         [ 4.1902e-01, -1.3368e-01,  4.0586e-01],\n",
      "         [ 2.9793e-01,  1.2026e-01,  3.8098e-02],\n",
      "         [ 2.7669e-01,  8.6304e-02,  1.1259e-01],\n",
      "         [ 1.9658e-01, -2.5976e-01,  4.2593e-01],\n",
      "         [ 9.6162e-02, -2.9486e-01,  5.7441e-01],\n",
      "         [ 7.9621e-02,  2.3631e-01, -3.1721e-01],\n",
      "         [-4.4453e-02,  2.2399e-03, -2.5380e-01],\n",
      "         [-1.5084e-01, -3.6257e-02,  3.8256e-01],\n",
      "         [-2.6998e-01,  9.1697e-02,  6.8943e-02],\n",
      "         [-3.7033e-01, -9.3134e-03, -2.8218e-01],\n",
      "         [-6.0524e-01,  8.8114e-02,  7.0574e-02],\n",
      "         [-8.2239e-01, -7.6559e-02,  4.7448e-01],\n",
      "         [-9.3386e-01,  3.6790e-01, -8.3049e-02],\n",
      "         [-1.1545e+00, -3.4399e-02,  1.5143e-01],\n",
      "         [-1.2485e+00, -6.3136e-01,  3.7749e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00]]]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]]) tensor([1]) tensor([83315])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4)\n",
    "for batch in dataloader:\n",
    "    print(batch[0].shape, batch[1].shape, batch[2].shape, batch[3].shape)\n",
    "    print(batch[0], batch[1], batch[2], batch[3])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f39fd3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(file['pf_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f04ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassJetDataset(Dataset):\n",
    "    def __init__(self, h5FilePath, \n",
    "                 n_load = -1\n",
    "                 ):\n",
    "        self.h5FilePath = h5FilePath\n",
    "        self.n_load = n_load\n",
    "        with h5py.File(self.h5FilePath, \"r\") as f:\n",
    "            self.pf_features = torch.from_numpy(f[\"pf_features\"][:n_load])\n",
    "            \n",
    "            if self.pf_features.shape[1] == 17 or self.pf_features.shape[-1] == 128:\n",
    "                self.pf_features = self.pf_features.permute(0, 2, 1)\n",
    "                print (f\"The input shape is WRONG. Corrected to {self.pf_features.shape}\")\n",
    "            \n",
    "            self.pf_mask = torch.from_numpy(f[\"pf_mask\"][:n_load])\n",
    "            \n",
    "            if self.pf_mask.shape[1] == 1:\n",
    "                print (f\"The mask shape is wrong and is of shape {self.pf_mask.shape}\")\n",
    "                self.pf_mask = self.pf_mask.squeeze(1)\n",
    "                print (f\"Converted the shape of mask to {self.pf_mask.shape}\")\n",
    "            \n",
    "            self.labels = torch.from_numpy(f[\"label\"][:n_load]).long()\n",
    "            \n",
    "            # TO DO \n",
    "            # MAKE THE SELECTION MORE GENERIC BASED ON LAEBLS. \n",
    "            # iF labels [0, 1, 5] is given choose only thsioe for training\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.shape[0]\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.pf_features = self.pf_features.to(device)\n",
    "        self.pf_mask = self.pf_mask.to(device)\n",
    "        self.labels = self.labels.to(device)\n",
    "    \n",
    "    def device(self):\n",
    "        return self.pf_features.device\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.pf_features[idx], self.pf_mask[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06696821",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MultiClassJetDataset(\"/sciclone/home/hnayak/scr10/Transfer_Learning/data/jetclass_train_preprocessed.h5\", n_load=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4250b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(ds, batch_size=32, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19d21345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 128, 3]) torch.Size([32, 128]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for i, m, o in train_loader:\n",
    "    print(i.shape, m.shape, o.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ROOT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
